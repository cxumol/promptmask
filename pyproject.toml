# pyproject.toml

[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "promptmask"
version = "0.1.0"
authors = [
    { name = "cxumol", email = "cxumol@gmail.com" },
]
description = "Keep your secret while chatting with AI by redacting/unredacting sensitive data using a local LLM."
readme = "README.md"
requires-python = ">=3.8"
classifiers = [
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
]
dependencies = [
    "openai>=1.10",
    "httpx>=0.25",
    "tomli; python_version < '3.11'",
]

[project.urls]
Homepage = "https://github.com/cxumol/promptmask"
Issues = "https://github.com/cxumol/promptmask/issues"

[project.optional-dependencies]
web = [
    "tomli-w",
    "fastapi>=0.100",
    "uvicorn[standard]>=0.20",
]
dev = [
    "ruff",
    "tqdm",
    "icecream",
    "pytest",
    "pytest-asyncio"
]

[project.scripts]
promptmask-web = "promptmask.web.main:run_server"

[tool.setuptools.packages.find]
where = ["src"]

[tool.setuptools.package-data]
promptmask = ["*.toml"]
"promptmask.web" = ["static/*"]